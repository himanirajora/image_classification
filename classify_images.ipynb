{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from imutils import paths\n",
    "import cv2, os\n",
    "\n",
    "\n",
    "TRAIN_DIR = \"./train\"\n",
    "MODEL_DIR = \"./models\"\n",
    "TEST_DIR = \"./Nishant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read train images\n",
    "IMAGE_DIMS = (64, 64, 3)\n",
    "\n",
    "imagePaths = sorted(list(paths.list_images(TRAIN_DIR)))\n",
    "data = []\n",
    "labels = []\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    " \n",
    "    # extract set of class labels from the image path and update the\n",
    "    # labels list\n",
    "    l = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pre- process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert into arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "data=preprocess_input(data)\n",
    "\n",
    "## label encoding\n",
    "le = LabelEncoder()\n",
    "labels_int = le.fit_transform(labels)\n",
    "labels_en = to_categorical(labels_int)\n",
    "\n",
    "# split data into train and validation\n",
    "X_train, X_valid, Y_train, Y_valid=train_test_split(data,labels_en,test_size=0.1, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling\n",
    "- freeze the weights of the first 8 layers of the vgg16 network, while we retrain the subsequent layers and add new fc layers to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_model(height, width, depth, num_classes=None, lr_rate = 0.01):\n",
    "\n",
    "    base_model = keras.applications.VGG16(weights='imagenet', include_top=False,\n",
    "                                          input_shape = (width, height, depth))\n",
    "    print(\"Weights loaded\")\n",
    "\n",
    "    top_model = Sequential()\n",
    "\n",
    "    top_model.add(Flatten(input_shape = base_model.output_shape[1:]))\n",
    "    \n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    \n",
    "    top_model.add(Dropout(0.2))\n",
    "    \n",
    "    top_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "    #To set the first 8 layers to non-trainable (weights will not be updated)\n",
    "\n",
    "    for layer in model.layers[:13]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    opt = Adam(lr=lr_rate, decay=1e-6)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_23 (Sequential)   (None, 11)                527371    \n",
      "=================================================================\n",
      "Total params: 15,242,059\n",
      "Trainable params: 9,966,603\n",
      "Non-trainable params: 5,275,456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 11\n",
    "batch_size = 32 \n",
    "epochs = 10\n",
    "\n",
    "# load model\n",
    "model = vgg16_model(IMAGE_DIMS[1], IMAGE_DIMS[0], IMAGE_DIMS[2], num_classes)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38784 samples, validate on 4310 samples\n",
      "Epoch 1/10\n",
      "38784/38784 [==============================] - 2629s 68ms/step - loss: 14.3054 - acc: 0.1124 - val_loss: 14.4913 - val_acc: 0.1009\n",
      "Epoch 2/10\n",
      "38784/38784 [==============================] - 2629s 68ms/step - loss: 14.2995 - acc: 0.1128 - val_loss: 14.4913 - val_acc: 0.1009\n",
      "Epoch 3/10\n",
      "38784/38784 [==============================] - 37036s 955ms/step - loss: 14.2829 - acc: 0.1139 - val_loss: 14.4913 - val_acc: 0.1009\n",
      "Epoch 4/10\n",
      " 7904/38784 [=====>........................] - ETA: 2:01:07 - loss: 14.2542 - acc: 0.1156"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, Y_train,batch_size=batch_size,epochs=epochs,\n",
    "          shuffle=True,verbose=1,validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
